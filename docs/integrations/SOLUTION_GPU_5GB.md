# Solution pour GPU 5GB - Qwen2.5-3B

**Probl√®me:** Qwen2.5-7B trop gros pour GPU 5GB (n√©cessite 12-16GB)
**Solution:** Utiliser Qwen2.5-3B (n√©cessite 4-5GB) ‚úÖ

---

## üéØ Comparaison des Options

| Mod√®le | VRAM Requis | Temps GPU 5GB | Temps CPU | Qualit√© Attendue |
|--------|-------------|---------------|-----------|------------------|
| **Qwen2.5-1.5B** | 2-3GB | ‚úÖ 30-60 min | 2-4h | 68.2% (d√©j√† fait) |
| **Qwen2.5-3B** | 4-5GB | ‚úÖ 1-2 heures | 4-8h | **85-88%** üéØ |
| **Qwen2.5-7B** | 12-16GB | ‚ùå OOM | 10-20h | 91-95% |

---

## ‚úÖ Recommandation: Qwen2.5-3B

### Pourquoi 3B est le meilleur choix pour vous?

**1. Compatible avec votre GPU 5GB**
- Qwen2.5-3B n√©cessite ~4-5GB VRAM
- Votre RTX 4050: 5GB disponible
- ‚úÖ √áa passe juste!

**2. Performance excellente**
- Attendu: **85-88%** overall quality
- vs Baseline 68.2%: **+17-20%** üéâ
- vs Target 7B 91-95%: **-6-7%** (acceptable!)

**3. Temps raisonnable**
- GPU 5GB: **1-2 heures** ‚ö°
- vs CPU 10-20h pour 7B
- vs CPU 4-8h pour 3B

**4. Benchmarks Qwen2.5-3B (mod√®le complet)**
```
MMLU:      71.8%  (tr√®s bon pour 3B!)
GSM8K:     83.4%  (excellent)
HumanEval: 82.3%  (impressionnant)
```

---

## üöÄ D√©marrage Rapide (1-2h avec votre GPU)

### √âtape 1: Setup (5 min)
```bash
./setup_qwen25_7b_env.sh  # M√™me script, d√©pendances identiques
```

### √âtape 2: Distillation Qwen2.5-3B (1-2h)
```bash
python3 distill_qwen25_3b.py
```

**Pas besoin de forcer CPU!** Votre GPU 5GB suffit pour 3B.

### √âtape 3: Tests (2 min)
```bash
# Cr√©er le script de test pour 3B
cp test_qwen25_7b_model.py test_qwen25_3b_model.py

# √âditer pour changer le path
sed -i 's/qwen25-7b-deposium-1024d/qwen25-3b-deposium-1024d/g' test_qwen25_3b_model.py

# Lancer
python3 test_qwen25_3b_model.py
```

### √âtape 4: √âvaluation (5 min)
```bash
# Cr√©er le script d'√©val pour 3B
cp quick_eval_qwen25_7b_1024d.py quick_eval_qwen25_3b_1024d.py

# √âditer pour changer le path
sed -i 's/qwen25-7b-deposium-1024d/qwen25-3b-deposium-1024d/g' quick_eval_qwen25_3b_1024d.py

# Lancer
python3 quick_eval_qwen25_3b_1024d.py
```

---

## üìä Performance Attendue

### Qwen2.5-3B Model2Vec (Estimations)

| Cat√©gorie | Qwen2.5-1.5B | Qwen2.5-3B (attendu) | Am√©lioration |
|-----------|--------------|----------------------|--------------|
| **Overall** | 68.2% | **85-88%** | **+17-20%** |
| Instruction Awareness | 95.3% | 96-97% | +1-2% |
| Semantic Similarity | 95.0% | 95-96% | +1% |
| Code Understanding | 86.4% | 91-93% | +5-7% |
| Domain Knowledge | 65-70% | 82-85% | +15-17% |
| Multilingual | 60-65% | 78-82% | +15-18% |

### Comparaison avec Target 7B

**Qwen2.5-3B:** 85-88% (1-2h sur votre GPU)
**Qwen2.5-7B:** 91-95% (10-20h CPU ou cloud)

**Trade-off:** -6-7% pour √©conomiser 8-18 heures üéØ

---

## üí° Pourquoi pas Unsloth?

**Unsloth est excellent mais pas applicable ici:**

1. **Unsloth = Fine-tuning**
   - Optimise LoRA, QLoRA, full fine-tuning
   - R√©duit VRAM de 70% pour l'entra√Ænement
   - Utilis√© pour adapter un mod√®le √† vos donn√©es

2. **Model2Vec = Distillation statique**
   - Une seule passe, pas de training
   - Pas de gradient descent
   - Convertit LLM ‚Üí embeddings statiques

3. **Pas compatible**
   - Model2Vec n'utilise pas les optimisations Unsloth
   - Deux workflows compl√®tement diff√©rents

**Quand utiliser Unsloth:**
- Fine-tuner Qwen2.5 sur vos propres donn√©es
- Adapter le mod√®le √† un domaine sp√©cifique
- Entra√Æner avec GPU limit√© (5GB)

**Ce qu'on fait ici:**
- Distillation Model2Vec (pas de training)
- Conversion LLM ‚Üí embeddings
- Unsloth n'aide pas

---

## üéØ D√©cision Finale

### Option A: Qwen2.5-3B (RECOMMAND√â ‚úÖ)

**Avantages:**
- ‚úÖ Compatible GPU 5GB
- ‚úÖ 1-2 heures seulement
- ‚úÖ 85-88% qualit√© (excellent!)
- ‚úÖ +17-20% vs baseline

**√Ä faire maintenant:**
```bash
python3 distill_qwen25_3b.py
```

### Option B: Qwen2.5-7B Cloud

**Si vous voulez absolument 91-95%:**
- Louer GPU cloud 16GB+
- AWS g5.xlarge: ~$1-2 pour 2-3h
- Paperspace A4000: ~$2.50 pour 3h

### Option C: Rester avec Qwen2.5-1.5B

**Si 68.2% suffit:**
- D√©j√† distill√©
- D√©j√† test√©
- D√©ployer directement

---

## ‚ö° Timeline Compl√®te (Qwen2.5-3B)

```
Aujourd'hui - Apr√®s-midi:
  14:00 - Setup environnement     (5 min)
  14:05 - Lancer distillation     (1 min)
  14:06 - ‚è∞ Attendre 1-2h

  16:00 - ‚úÖ Distillation termin√©e
  16:02 - Tests du mod√®le          (2 min)
  16:04 - √âvaluation compl√®te      (5 min)
  16:09 - üéâ TERMIN√â!

Total: ~2 heures 15 minutes
```

---

## üìã Commandes Compl√®tes

```bash
# 1. Setup (si pas d√©j√† fait)
./setup_qwen25_7b_env.sh

# 2. Distillation 3B (1-2h avec GPU)
python3 distill_qwen25_3b.py

# 3. Tests
cp test_qwen25_7b_model.py test_qwen25_3b_model.py
sed -i 's/7b/3b/g' test_qwen25_3b_model.py
python3 test_qwen25_3b_model.py

# 4. √âvaluation
cp quick_eval_qwen25_7b_1024d.py quick_eval_qwen25_3b_1024d.py
sed -i 's/7b/3b/g' quick_eval_qwen25_3b_1024d.py
python3 quick_eval_qwen25_3b_1024d.py

# 5. Si score ‚â• 85%, d√©ployer
cp deploy_qwen25_7b.sh deploy_qwen25_3b.sh
sed -i 's/7b/3b/g' deploy_qwen25_3b.sh
./deploy_qwen25_3b.sh
```

---

## üéâ R√©sum√©

**Probl√®me r√©solu:**
- Qwen2.5-7B trop gros ‚Üí Qwen2.5-3B parfait pour GPU 5GB

**Gain:**
- 1-2h au lieu de 10-20h ‚ö°
- 85-88% au lieu de 91-95% (-6-7% acceptable)
- GPU au lieu de CPU üéÆ

**Prochaine commande:**
```bash
python3 distill_qwen25_3b.py
```

---

**Date:** 2025-10-14
**Status:** ‚úÖ Ready to start
**Estimated time:** 1-2 hours
