#!/usr/bin/env python3
"""
Detailed Multilingual Testing for Granite 4.0 Micro
Tests: Cross-lingual retrieval, semantic similarity in 12 languages,
       translation quality, multilingual RAG
"""

import numpy as np
from pathlib import Path
from model2vec import StaticModel

print("=" * 80)
print("ğŸŒ MULTILINGUAL DEEP DIVE - Granite 4.0 Micro vs Competitors")
print("=" * 80)
print()

# Load models
models = {}
model_paths = {
    "Qwen2.5-1.5B (PROD)": "models/qwen25-deposium-1024d",
    "Granite 4.0 Micro (NEW)": "granite-4.0-micro-deposium-1024d",
}

print("ğŸ“¥ Loading models...")
for name, path in model_paths.items():
    model_dir = Path(path)
    if model_dir.exists():
        try:
            print(f"  Loading {name}...")
            models[name] = StaticModel.from_pretrained(str(model_dir))
            print(f"    âœ… Loaded")
        except Exception as e:
            print(f"    âŒ Failed: {e}")
    else:
        print(f"  âš ï¸  Not found: {path}")

if "Granite 4.0 Micro (NEW)" not in models:
    print()
    print("âŒ Granite model not found! Run distillation first:")
    print("   python3 distill_granite_4_0_micro.py")
    exit(1)

print()
print("=" * 80)
print("TEST 1: SEMANTIC SIMILARITY PER LANGUAGE")
print("=" * 80)
print()

# Language-specific tests
language_tests = {
    "English (EN)": [
        ("Artificial intelligence is transforming technology", "AI and machine learning revolutionize tech"),
        ("The weather is sunny and warm", "It's a beautiful day with sunshine"),
        ("Python programming language", "Coding in Python"),
    ],
    "French (FR)": [
        ("L'intelligence artificielle transforme la technologie", "L'IA et le machine learning rÃ©volutionnent la tech"),
        ("Il fait beau et chaud", "C'est une belle journÃ©e ensoleillÃ©e"),
        ("Langage de programmation Python", "Programmer en Python"),
    ],
    "German (DE)": [
        ("KÃ¼nstliche Intelligenz verÃ¤ndert Technologie", "KI und maschinelles Lernen revolutionieren Technik"),
        ("Das Wetter ist sonnig und warm", "Es ist ein schÃ¶ner Tag mit Sonnenschein"),
        ("Python Programmiersprache", "Programmieren in Python"),
    ],
    "Spanish (ES)": [
        ("La inteligencia artificial transforma la tecnologÃ­a", "La IA y el aprendizaje automÃ¡tico revolucionan la tecnologÃ­a"),
        ("El clima es soleado y cÃ¡lido", "Es un hermoso dÃ­a con sol"),
        ("Lenguaje de programaciÃ³n Python", "Programar en Python"),
    ],
    "Chinese (ZH)": [
        ("äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æŠ€æœ¯", "AIå’Œæœºå™¨å­¦ä¹ é©æ–°ç§‘æŠ€"),
        ("å¤©æ°”æ™´æœ—æ¸©æš–", "ä»Šå¤©é˜³å…‰æ˜åªš"),
        ("Pythonç¼–ç¨‹è¯­è¨€", "ç”¨Pythonç¼–ç¨‹"),
    ],
    "Japanese (JP)": [
        ("äººå·¥çŸ¥èƒ½ãŒæŠ€è¡“ã‚’å¤‰ãˆã¦ã„ã¾ã™", "AIã¨æ©Ÿæ¢°å­¦ç¿’ãŒæŠ€è¡“é©æ–°ã‚’èµ·ã“ã—ã¦ã„ã¾ã™"),
        ("å¤©æ°—ã¯æ™´ã‚Œã¦æš–ã‹ã„", "ç´ æ™´ã‚‰ã—ã„æ™´ã‚ŒãŸæ—¥ã§ã™"),
        ("Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª", "Pythonã§ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°"),
    ],
}

print("Test: Semantic similarity within each language")
print()

language_results = {}

for lang, test_pairs in language_tests.items():
    print(f"ğŸ“– Testing {lang}:")

    for name, model in models.items():
        scores = []

        for text1, text2 in test_pairs:
            emb1 = model.encode([text1])[0]
            emb2 = model.encode([text2])[0]

            similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))
            scores.append(similarity)

        avg_score = np.mean(scores)

        if name not in language_results:
            language_results[name] = {}
        language_results[name][lang] = avg_score

        print(f"  {name}: {avg_score:.4f} ({avg_score*100:.2f}%)")

    print()

print("=" * 80)
print("ğŸ“Š Summary by Language:")
print("=" * 80)
print()

for name in models:
    print(f"{name}:")
    for lang, score in language_results[name].items():
        print(f"  {lang}: {score*100:.2f}%")
    print()

print()
print("=" * 80)
print("TEST 2: CROSS-LINGUAL RETRIEVAL")
print("=" * 80)
print()

# Cross-lingual test: Query in one language, documents in another
cross_lingual_tests = [
    {
        "query_lang": "EN",
        "query": "What is machine learning?",
        "doc_lang": "FR",
        "documents": [
            "Le machine learning est une branche de l'intelligence artificielle",
            "Les bases de donnÃ©es stockent des informations",
            "La cybersÃ©curitÃ© protÃ¨ge les donnÃ©es",
        ],
        "correct_idx": 0,
    },
    {
        "query_lang": "FR",
        "query": "Qu'est-ce que Python?",
        "doc_lang": "EN",
        "documents": [
            "Python is a high-level programming language",
            "Databases store structured data",
            "Cloud computing provides scalable resources",
        ],
        "correct_idx": 0,
    },
    {
        "query_lang": "EN",
        "query": "Climate change impacts",
        "doc_lang": "ES",
        "documents": [
            "El cambio climÃ¡tico afecta al planeta",
            "La programaciÃ³n en Python es popular",
            "Las bases de datos almacenan informaciÃ³n",
        ],
        "correct_idx": 0,
    },
]

print("Test: Query in one language, retrieve documents in another language")
print()

cross_lingual_results = {name: [] for name in models}

for test in cross_lingual_tests:
    query = test["query"]
    documents = test["documents"]
    correct_idx = test["correct_idx"]

    print(f"Query [{test['query_lang']}]: '{query}'")
    print(f"Documents [{test['doc_lang']}]:")
    for i, doc in enumerate(documents):
        marker = "âœ“" if i == correct_idx else " "
        print(f"  [{marker}] {doc}")
    print()

    for name, model in models.items():
        query_emb = model.encode([query])[0]
        doc_embs = model.encode(documents)

        similarities = []
        for doc_emb in doc_embs:
            sim = np.dot(query_emb, doc_emb) / (np.linalg.norm(query_emb) * np.linalg.norm(doc_emb))
            similarities.append(sim)

        top_idx = np.argmax(similarities)
        is_correct = top_idx == correct_idx
        cross_lingual_results[name].append(1.0 if is_correct else 0.0)

        status = "âœ…" if is_correct else "âŒ"
        print(f"  {name}: {status} Retrieved doc {top_idx} (sim: {similarities[top_idx]:.4f})")

    print()

print("ğŸ“Š Cross-Lingual Retrieval Accuracy:")
for name in models:
    accuracy = np.mean(cross_lingual_results[name]) * 100
    print(f"  {name}: {accuracy:.2f}% ({int(sum(cross_lingual_results[name]))}/{len(cross_lingual_results[name])} correct)")

print()
print("=" * 80)
print("TEST 3: MULTILINGUAL RAG SIMULATION")
print("=" * 80)
print()

# Multilingual knowledge base
multilingual_kb = [
    ("EN", "Python is a versatile programming language used for web development, data science, and automation"),
    ("FR", "Le deep learning est une technique d'apprentissage automatique utilisant des rÃ©seaux de neurones profonds"),
    ("DE", "Datenbanken sind Systeme zum Speichern und Verwalten strukturierter Informationen"),
    ("ES", "La computaciÃ³n en la nube proporciona recursos escalables a travÃ©s de internet"),
    ("ZH", "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºæ™ºèƒ½æœºå™¨"),
    ("EN", "Machine learning algorithms learn patterns from data without explicit programming"),
]

queries_multilingual = [
    ("EN", "Tell me about Python programming", 0),  # Should match EN Python doc
    ("FR", "Qu'est-ce que le deep learning?", 1),  # Should match FR deep learning doc
    ("DE", "Was sind Datenbanken?", 2),  # Should match DE database doc
    ("EN", "What is machine learning?", 5),  # Should match EN ML doc
]

print("Test: Multilingual RAG with mixed-language knowledge base")
print()

print("ğŸ“š Knowledge Base:")
for i, (lang, doc) in enumerate(multilingual_kb):
    print(f"  [{i}] [{lang}] {doc[:60]}...")
print()

rag_results = {name: [] for name in models}

for query_lang, query, correct_idx in queries_multilingual:
    print(f"Query [{query_lang}]: '{query}'")

    for name, model in models.items():
        query_emb = model.encode([query])[0]

        # Encode all documents (regardless of language)
        doc_texts = [doc for _, doc in multilingual_kb]
        doc_embs = model.encode(doc_texts)

        similarities = []
        for doc_emb in doc_embs:
            sim = np.dot(query_emb, doc_emb) / (np.linalg.norm(query_emb) * np.linalg.norm(doc_emb))
            similarities.append(sim)

        top_idx = np.argmax(similarities)
        is_correct = top_idx == correct_idx
        rag_results[name].append(1.0 if is_correct else 0.0)

        status = "âœ…" if is_correct else "âŒ"
        top_lang, top_doc = multilingual_kb[top_idx]
        print(f"  {name}: {status} [{top_lang}] {top_doc[:50]}... (sim: {similarities[top_idx]:.4f})")

    print()

print("ğŸ“Š Multilingual RAG Accuracy:")
for name in models:
    accuracy = np.mean(rag_results[name]) * 100
    print(f"  {name}: {accuracy:.2f}% ({int(sum(rag_results[name]))}/{len(rag_results[name])} correct)")

print()
print("=" * 80)
print("ğŸ† FINAL MULTILINGUAL VERDICT")
print("=" * 80)
print()

# Calculate overall multilingual score
granite_name = "Granite 4.0 Micro (NEW)"
qwen_name = "Qwen2.5-1.5B (PROD)"

if granite_name in models and qwen_name in models:
    # Average across all languages
    granite_lang_avg = np.mean(list(language_results[granite_name].values())) * 100
    qwen_lang_avg = np.mean(list(language_results[qwen_name].values())) * 100

    # Cross-lingual accuracy
    granite_cross = np.mean(cross_lingual_results[granite_name]) * 100
    qwen_cross = np.mean(cross_lingual_results[qwen_name]) * 100

    # RAG accuracy
    granite_rag = np.mean(rag_results[granite_name]) * 100
    qwen_rag = np.mean(rag_results[qwen_name]) * 100

    print(f"ğŸ“Š Overall Multilingual Performance:")
    print()
    print(f"{'Metric':<30} {qwen_name:<20} {granite_name:<25} {'Winner':<10}")
    print("-" * 90)
    print(f"{'Per-language similarity':<30} {qwen_lang_avg:>6.2f}%            {granite_lang_avg:>6.2f}%              {'Granite' if granite_lang_avg > qwen_lang_avg else 'Qwen':<10}")
    print(f"{'Cross-lingual retrieval':<30} {qwen_cross:>6.2f}%            {granite_cross:>6.2f}%              {'Granite' if granite_cross > qwen_cross else 'Qwen':<10}")
    print(f"{'Multilingual RAG':<30} {qwen_rag:>6.2f}%            {granite_rag:>6.2f}%              {'Granite' if granite_rag > qwen_rag else 'Qwen':<10}")
    print()

    # Composite score
    granite_composite = (granite_lang_avg + granite_cross + granite_rag) / 3
    qwen_composite = (qwen_lang_avg + qwen_cross + qwen_rag) / 3

    print(f"ğŸ¯ Composite Multilingual Score:")
    print(f"  {qwen_name}: {qwen_composite:.2f}%")
    print(f"  {granite_name}: {granite_composite:.2f}%")
    print()

    if granite_composite > qwen_composite:
        diff = granite_composite - qwen_composite
        print(f"âœ… GRANITE WINS for multilingual use cases!")
        print(f"   Improvement: +{diff:.2f}% over Qwen2.5-1.5B")
        print()
        print(f"   Granite excels in:")
        if granite_lang_avg > qwen_lang_avg:
            print(f"   - Per-language quality (+{granite_lang_avg - qwen_lang_avg:.2f}%)")
        if granite_cross > qwen_cross:
            print(f"   - Cross-lingual retrieval (+{granite_cross - qwen_cross:.2f}%)")
        if granite_rag > qwen_rag:
            print(f"   - Multilingual RAG (+{granite_rag - qwen_rag:.2f}%)")
    else:
        diff = qwen_composite - granite_composite
        print(f"âš ï¸  QWEN WINS even for multilingual!")
        print(f"   Lead: +{diff:.2f}% over Granite")
        print()
        print(f"   Consider Granite only if you NEED 12-language support")

print()
print("=" * 80)
print("ğŸ“„ Saving detailed results...")
print("=" * 80)

# Save to file
with open("granite_multilingual_results.txt", "w") as f:
    f.write("=" * 80 + "\n")
    f.write("GRANITE 4.0 MICRO - MULTILINGUAL ANALYSIS\n")
    f.write("=" * 80 + "\n\n")

    f.write("PER-LANGUAGE RESULTS:\n")
    f.write("-" * 80 + "\n")
    for name in models:
        f.write(f"\n{name}:\n")
        for lang, score in language_results[name].items():
            f.write(f"  {lang}: {score*100:.2f}%\n")

    f.write("\n" + "=" * 80 + "\n")
    f.write("CROSS-LINGUAL RETRIEVAL:\n")
    f.write("-" * 80 + "\n")
    for name in models:
        accuracy = np.mean(cross_lingual_results[name]) * 100
        f.write(f"{name}: {accuracy:.2f}%\n")

    f.write("\n" + "=" * 80 + "\n")
    f.write("MULTILINGUAL RAG:\n")
    f.write("-" * 80 + "\n")
    for name in models:
        accuracy = np.mean(rag_results[name]) * 100
        f.write(f"{name}: {accuracy:.2f}%\n")

print("âœ… Results saved to: granite_multilingual_results.txt")
print()
