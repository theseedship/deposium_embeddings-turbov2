================================================================================
üî¨ COMPLETE MODEL COMPARISON - 4 Models + Multilingual Tests
================================================================================

üì• Loading models...
  Loading Qwen2.5-1.5B (PROD)...
    ‚úÖ Loaded (302.2MB)
  Loading Qwen2.5-3B...
    ‚úÖ Loaded (302.2MB)
  Loading Granite 4.0 Micro (NEW)...
    ‚úÖ Loaded (199.6MB)
  Loading Gemma-768D...
    ‚úÖ Loaded (382.8MB)

================================================================================
TEST 1: SEMANTIC SIMILARITY (Quality Test)
================================================================================

Test: Measure semantic similarity between related sentences

Pair: 'Machine learning is fascinating...' vs 'AI and deep learning are interesting...'
  Qwen2.5-1.5B (PROD): 0.9595
  Qwen2.5-3B: 0.9602
  Granite 4.0 Micro (NEW): 0.9746
  Gemma-768D: 0.6816

Pair: 'The weather is nice today...' vs 'It's sunny and warm outside...'
  Qwen2.5-1.5B (PROD): 0.9382
  Qwen2.5-3B: 0.9465
  Granite 4.0 Micro (NEW): 0.9329
  Gemma-768D: 0.5850

Pair: 'Python programming language...' vs 'Coding in Python...'
  Qwen2.5-1.5B (PROD): 0.9040
  Qwen2.5-3B: 0.8953
  Granite 4.0 Micro (NEW): 0.9672
  Gemma-768D: 0.7314

Pair: 'Database optimization techniques...' vs 'SQL query performance tuning...'
  Qwen2.5-1.5B (PROD): 0.9149
  Qwen2.5-3B: 0.8926
  Granite 4.0 Micro (NEW): 0.5843
  Gemma-768D: 0.4260

Pair: 'Climate change impacts...' vs 'Global warming effects...'
  Qwen2.5-1.5B (PROD): 0.9566
  Qwen2.5-3B: 0.9513
  Granite 4.0 Micro (NEW): 0.7451
  Gemma-768D: 0.5225

üìä Average Semantic Similarity:
  Qwen2.5-1.5B (PROD): 0.9346 (93.46%)
  Qwen2.5-3B: 0.9292 (92.92%)
  Granite 4.0 Micro (NEW): 0.8408 (84.08%)
  Gemma-768D: 0.5894 (58.94%)

================================================================================
TEST 2: INSTRUCTION-AWARENESS (Unique Model2Vec capability)
================================================================================

Test: Can model distinguish instruction from topic?
Higher score = better instruction-awareness

Instruction: 'Explain quantum computing' vs Topic: 'quantum computing'
  Qwen2.5-1.5B (PROD): 0.0322 (sim: 0.9678)
  Qwen2.5-3B: 0.0205 (sim: 0.9795)
  Granite 4.0 Micro (NEW): 0.0166 (sim: 0.9834)
  Gemma-768D: 0.2437 (sim: 0.7563)

Instruction: 'Find restaurants near me' vs Topic: 'restaurant'
  Qwen2.5-1.5B (PROD): 0.1253 (sim: 0.8747)
  Qwen2.5-3B: 0.1816 (sim: 0.8184)
  Granite 4.0 Micro (NEW): 0.3153 (sim: 0.6847)
  Gemma-768D: 0.4072 (sim: 0.5928)

Instruction: 'Compare iPhone vs Android' vs Topic: 'iPhone Android comparison'
  Qwen2.5-1.5B (PROD): 0.0913 (sim: 0.9087)
  Qwen2.5-3B: 0.1015 (sim: 0.8985)
  Granite 4.0 Micro (NEW): 0.0401 (sim: 0.9599)
  Gemma-768D: 0.0874 (sim: 0.9126)

Instruction: 'Summarize climate change' vs Topic: 'climate change summary'
  Qwen2.5-1.5B (PROD): 0.0968 (sim: 0.9032)
  Qwen2.5-3B: 0.0776 (sim: 0.9224)
  Granite 4.0 Micro (NEW): 0.3025 (sim: 0.6975)
  Gemma-768D: 0.0884 (sim: 0.9116)

Instruction: 'Translate hello to French' vs Topic: 'hello French translation'
  Qwen2.5-1.5B (PROD): 0.0393 (sim: 0.9607)
  Qwen2.5-3B: 0.0517 (sim: 0.9483)
  Granite 4.0 Micro (NEW): 0.0859 (sim: 0.9141)
  Gemma-768D: 0.0396 (sim: 0.9604)

üìä Average Instruction-Awareness Score:
  Qwen2.5-1.5B (PROD): 0.0770 (7.70%)
  Qwen2.5-3B: 0.0866 (8.66%)
  Granite 4.0 Micro (NEW): 0.1521 (15.21%)
  Gemma-768D: 0.1732 (17.33%)

================================================================================
TEST 3: SPEED BENCHMARK (Inference performance)
================================================================================

Test: Encode 100 texts and measure time

Testing Qwen2.5-1.5B (PROD)...
  Duration: 0.003s
  Throughput: 33527.6 texts/sec

Testing Qwen2.5-3B...
  Duration: 0.004s
  Throughput: 28563.8 texts/sec

Testing Granite 4.0 Micro (NEW)...
  Duration: 0.004s
  Throughput: 26947.0 texts/sec

Testing Gemma-768D...
  Duration: 0.004s
  Throughput: 27930.4 texts/sec


================================================================================
TEST 4: DOCUMENT RETRIEVAL (RAG simulation)
================================================================================

Test: Retrieve relevant documents for queries (RAG use case)

Query: 'What is Python used for?'
  Qwen2.5-1.5B (PROD): Top match = 'Cloud computing provides scalable resources...' (sim: 0.9426)
  Qwen2.5-3B: Top match = 'Cloud computing provides scalable resources...' (sim: 0.9201)
  Granite 4.0 Micro (NEW): Top match = 'Neural networks mimic brain structure...' (sim: 0.9734)
  Gemma-768D: Top match = 'Python is a high-level programming language...' (sim: 0.3726)

Query: 'How does machine learning work?'
  Qwen2.5-1.5B (PROD): Top match = 'Machine learning algorithms learn from data...' (sim: 0.9616)
  Qwen2.5-3B: Top match = 'Machine learning algorithms learn from data...' (sim: 0.9577)
  Granite 4.0 Micro (NEW): Top match = 'Machine learning algorithms learn from data...' (sim: 0.8724)
  Gemma-768D: Top match = 'Machine learning algorithms learn from data...' (sim: 0.5947)

Query: 'Tell me about databases'
  Qwen2.5-1.5B (PROD): Top match = 'Machine learning algorithms learn from data...' (sim: 0.9486)
  Qwen2.5-3B: Top match = 'Machine learning algorithms learn from data...' (sim: 0.9081)
  Granite 4.0 Micro (NEW): Top match = 'Databases store and organize information...' (sim: 0.7801)
  Gemma-768D: Top match = 'Databases store and organize information...' (sim: 0.4275)

üìä Average Retrieval Quality:
  Qwen2.5-1.5B (PROD): 0.9509 (95.09%)
  Qwen2.5-3B: 0.9287 (92.87%)
  Granite 4.0 Micro (NEW): 0.8753 (87.53%)
  Gemma-768D: 0.4648 (46.50%)

================================================================================
TEST 5: MULTILINGUAL CAPABILITY (üåç NEW TEST)
================================================================================

Test: Semantic similarity in multiple languages
(Granite 4.0 Micro is natively multilingual - 12 languages)

[EN] 'Machine learning is transforming AI...' vs 'AI and machine learning are revolutionar...'
  Qwen2.5-1.5B (PROD): 0.9755
  Qwen2.5-3B: 0.9614
  Granite 4.0 Micro (NEW): 0.9874
  Gemma-768D: 0.8062

[FR] 'Le deep learning r√©volutionne l'IA...' vs 'L'IA et le deep learning sont r√©volution...'
  Qwen2.5-1.5B (PROD): 0.9598
  Qwen2.5-3B: 0.9524
  Granite 4.0 Micro (NEW): 0.8721
  Gemma-768D: 0.8511

[DE] 'Das maschinelle Lernen ver√§ndert KI...' vs 'KI und maschinelles Lernen sind revoluti...'
  Qwen2.5-1.5B (PROD): 0.9722
  Qwen2.5-3B: 0.9472
  Granite 4.0 Micro (NEW): 0.7788
  Gemma-768D: 0.6318

[ES] 'El aprendizaje autom√°tico transforma la ...' vs 'La IA y el aprendizaje autom√°tico son re...'
  Qwen2.5-1.5B (PROD): 0.9859
  Qwen2.5-3B: 0.9706
  Granite 4.0 Micro (NEW): 0.7716
  Gemma-768D: 0.7544

[ZH] 'Êú∫Âô®Â≠¶‰π†Ê≠£Âú®ÊîπÂèò‰∫∫Â∑•Êô∫ËÉΩ...' vs '‰∫∫Â∑•Êô∫ËÉΩÂíåÊú∫Âô®Â≠¶‰π†ÂÖ∑ÊúâÈù©ÂëΩÊÄß...'
  Qwen2.5-1.5B (PROD): 0.9876
  Qwen2.5-3B: 0.9657
  Granite 4.0 Micro (NEW): 0.9989
  Gemma-768D: 0.5303

üìä Average Multilingual Quality:
  Qwen2.5-1.5B (PROD): 0.9762 (97.62%)
  Qwen2.5-3B: 0.9595 (95.95%)
  Granite 4.0 Micro (NEW): 0.8817 (88.17%)
  Gemma-768D: 0.7148 (71.50%)

================================================================================
üìä FINAL COMPARISON SUMMARY
================================================================================

Model                     Quality    Instruct   Multilng   Speed        Size      
------------------------------------------------------------------------------------------
Qwen2.5-1.5B (PROD)        93.46%     7.70%    97.62%    33527.6 t/s   302.2MB
Qwen2.5-3B                 92.92%     8.66%    95.95%    28563.8 t/s   302.2MB
Granite 4.0 Micro (NEW)    84.08%    15.21%    88.17%    26947.0 t/s   199.6MB
Gemma-768D                 58.94%    17.33%    71.50%    27930.4 t/s   382.8MB

================================================================================
üèÜ RECOMMENDATION
================================================================================

üìä Key Metrics Comparison:
   Qwen2.5-1.5B (CURRENT): 93.46% quality, 97.62% multilingual
   Granite 4.0 Micro (NEW): 84.08% quality, 88.17% multilingual

‚ö†Ô∏è  KEEP CURRENT MODEL (Qwen2.5-1.5B)
   Current: 93.46% quality
   Granite: 84.08% quality
   Difference: -9.38%

   Recommendation: Wait for Qwen2.5-7B (expected 91-95%)

================================================================================
Next Steps:
================================================================================

1. ‚è≥ Archive Granite results for reference
2. Test other models: Llama 3.2 3B, Phi-3.5-mini, Mistral-Small
3. Or wait for Qwen2.5-7B on HuggingFace Spaces

üìÑ Results saved to: granite_comparison_results.txt

