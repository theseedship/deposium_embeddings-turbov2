# Archive Index - ColBERT Evaluation

**Model**: mxbai-edge-colbert-v0-32m
**Date**: 2025-10-18
**Status**: âŒ Rejected for integration (RAM overhead)
**Quality**: 94.4% (best tested, but +964MB RAM)

---

## ğŸ“ Structure des Fichiers

```
benchmarks/models/mxbai-edge-colbert-32m/
â”œâ”€â”€ DECISION.md                    # ğŸ“‹ Document de dÃ©cision finale (Ã€ LIRE)
â”œâ”€â”€ README.md                      # ğŸ“– SpÃ©cifications du modÃ¨le
â”œâ”€â”€ ARCHIVE_INDEX.md              # ğŸ“š Ce fichier - Index des archives
â”œâ”€â”€ results.txt                    # ğŸ“Š RÃ©sultats bruts des tests
â”‚
â”œâ”€â”€ test_colbert.py                # ğŸ§ª Test principal (qualitÃ© + performance)
â”œâ”€â”€ test_multilingual.py           # ğŸŒ Test multilingue (FR, ES, DE)
â”œâ”€â”€ inspect_model.py               # ğŸ” Inspection architecture
â”œâ”€â”€ get_full_config.py             # âš™ï¸ Configuration complÃ¨te
â”œâ”€â”€ distill_to_model2vec.py        # ğŸ”„ Tentative distillation (Ã©chec technique)
â”‚
â””â”€â”€ logs/
    â”œâ”€â”€ test_output.log            # ğŸ“ Logs du test principal
    â””â”€â”€ distillation.log           # ğŸ“ Logs tentative distillation
```

---

## ğŸ“„ Description des Fichiers

### Documents de DÃ©cision

**DECISION.md** (7.9K) â­ **DOCUMENT PRINCIPAL**
- Analyse complÃ¨te coÃ»t/bÃ©nÃ©fice
- Raisons du rejet dÃ©taillÃ©es
- Comparaison avec qwen25-1024d
- Recommandation finale

**README.md** (4.1K)
- SpÃ©cifications techniques du modÃ¨le
- Architecture ColBERT expliquÃ©e
- Avantages/InconvÃ©nients
- Statut de l'Ã©valuation

**ARCHIVE_INDEX.md** (ce fichier)
- Index de tous les fichiers d'Ã©valuation
- Guide de navigation dans l'archive

### RÃ©sultats

**results.txt** (1.4K)
- RÃ©sultats bruts des tests
- Scores de qualitÃ© (94.4%)
- MÃ©triques de performance
- Recommandation automatique

### Scripts de Test

**test_colbert.py** (13K) â­ **TEST PRINCIPAL**
- Test de qualitÃ© globale
- Semantic similarity
- Instruction awareness
- Code understanding
- Performance metrics

**test_multilingual.py** (3.8K)
- Test support multilingue
- FranÃ§ais, Espagnol, Allemand
- Comparaison avec Anglais (baseline)
- Verdict par langue

**inspect_model.py** (3.9K)
- Inspection de l'architecture
- Dimensions embeddings
- Context length
- Configuration dÃ©taillÃ©e

**get_full_config.py** (2.2K)
- Extraction config complÃ¨te HuggingFace
- Specs techniques dÃ©taillÃ©es
- Architecture ModernBERT

**distill_to_model2vec.py** (5.0K) âš ï¸ **Ã‰CHEC TECHNIQUE**
- Tentative de distillation vers Model2Vec
- Objectif: rÃ©duire RAM overhead
- RÃ©sultat: IncompatibilitÃ© architecture multi-vector
- Conclusion: Distillation impossible

### Logs

**logs/test_output.log** (14K)
- Log complet du test principal
- Incluant tous les rÃ©sultats dÃ©taillÃ©s
- Temps d'exÃ©cution: ~3 secondes

**logs/distillation.log** (9.1K)
- Log de la tentative de distillation
- Erreurs techniques (404 EntryNotFoundError)
- Preuve de l'incompatibilitÃ© architecture

---

## ğŸ¯ Points ClÃ©s Ã  Retenir

### âœ… Ce qui a fonctionnÃ©

1. **Tests de qualitÃ© excellents** : 94.4% overall (+26.2% vs qwen25)
2. **Instruction-awareness supÃ©rieur** : 95.6% (+0.7% vs qwen25)
3. **Code understanding excellent** : 94.0% (+9.5% vs qwen25)
4. **Support multilingue vÃ©rifiÃ©** : FR/ES/DE < 4% dÃ©gradation vs EN
5. **Performance acceptable** : 5.94 ms/text
6. **MÃ©thodologie de test robuste** : Reproductible et documentÃ©e

### âŒ Ce qui a Ã©chouÃ©

1. **Overhead RAM prohibitif** : +964MB (15x plus gros que qwen25: 65MB)
2. **Architecture incompatible** : Multi-vector vs single-vector
3. **Distillation impossible** : Model2Vec ne peut pas distiller multi-vector
4. **Wrapper "averaged" non viable** : MÃªme RAM, perd late interaction
5. **Rapport qualitÃ©/RAM insuffisant** : 0.098% /MB vs qwen25: 1.05% /MB

### ğŸ“š LeÃ§ons Apprises

1. **Multi-vector â‰  Single-vector** : Architectures fondamentalement diffÃ©rentes
2. **Edge-optimized â‰  Edge-deployable** : 32M params mais 964MB RAM
3. **QualitÃ© excellente â‰  IntÃ©gration garantie** : Infrastructure cost matter
4. **ColBERT = Reference gold standard** : 94.4% est notre nouveau benchmark
5. **qwen25-1024d = Excellent compromise** : ValidÃ© par cette Ã©valuation

---

## ğŸ”— RÃ©fÃ©rences

### Documentation AssociÃ©e

- **`../../COLBERT_TESTING.md`** : Guide complet ColBERT (mÃ©thodologie)
- **`../../README.md`** : Tableau comparatif tous modÃ¨les (section ColBERT)

### Liens Externes

- **Blog Mixedbread** : https://www.mixedbread.com/blog/edge-v0
- **HuggingFace** : https://huggingface.co/mixedbread-ai/mxbai-edge-colbert-v0-32m
- **PyLate Library** : https://github.com/lightonai/pylate
- **ColBERT Paper** : https://arxiv.org/abs/2004.12832

---

## ğŸ“Š Comparaison Finale

| MÃ©trique | qwen25-1024d (PROD) | ColBERT 32M (RejetÃ©) | Delta |
|----------|---------------------|----------------------|-------|
| Quality | 68.2% | **94.4%** | **+26.2%** âœ… |
| RAM | 65MB | 964MB | **+964MB** âŒ |
| Speed | <1ms (cache) | 5.94ms | +5ms âœ… |
| Instruction | 94.9% | 95.6% | +0.7% âœ… |
| Code | 84.5% | 94.0% | +9.5% âœ… |
| Multilingue | 39.4% | ~92% | +52.6% âœ… |
| Architecture | Single-vector | Multi-vector | Incompatible âŒ |
| **Quality/MB** | **1.05% /MB** | **0.098% /MB** | **-10.7x** âŒ |

**Verdict** : qwen25-1024d reste le meilleur choix pour edge deployment.

---

**Ã‰valuation par** : Claude Code
**ValidÃ©e par** : User (dÃ©cision RAM overhead)
**Date** : 2025-10-18
**Statut** : âœ… Archive complÃ¨te et documentÃ©e
