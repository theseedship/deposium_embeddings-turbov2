# mxbai-edge-colbert-v0-32m

## ğŸ“‹ Informations du ModÃ¨le

- **Nom complet**: mixedbread-ai/mxbai-edge-colbert-v0-32m
- **Architecture**: ColBERT (Contextualized Late Interaction)
- **ParamÃ¨tres**: 32 millions (32M)
- **Taille estimÃ©e**: ~128MB
- **Provider**: Mixedbread AI
- **Librairie**: PyLate (ColBERT implementation)

## ğŸ¯ ParticularitÃ©s

### ColBERT = Multi-Vector Embeddings

**DiffÃ©rence clÃ© avec nos modÃ¨les actuels**:
- **ModÃ¨les actuels** (qwen25, gemma): 1 vecteur par texte
- **ColBERT**: N vecteurs par texte (1 par token)

### Avantages

1. **PrÃ©cision supÃ©rieure**: Late interaction capture mieux le contexte
2. **Petit modÃ¨le**: 32M params vs 600M+ pour alternatives
3. **Edge-optimized**: ConÃ§u pour dÃ©ploiement resource-constrained
4. **Token-level matching**: Meilleur pour code search, Q&A

### InconvÃ©nients

1. **Plus lent**: MaxSim operation vs cosine similarity simple
2. **Plus complexe**: Architecture multi-vector
3. **Incompatible**: Avec clustering, certains benchmarks MTEB
4. **Cache diffÃ©rent**: Impossible de cacher single averaged vector

## ğŸ§ª Tests EffectuÃ©s

### 1. Semantic Similarity
Paires similaires vs dissimilaires pour mesurer sÃ©paration.

### 2. Instruction Awareness
Comparaison avec qwen25-1024d (94.9% baseline).

### 3. Code Understanding
Comparaison avec qwen25-1024d (84.5% baseline).

### 4. Performance
- RAM usage
- Encoding latency
- Model size

## ğŸ“Š RÃ©sultats

Voir `results.txt` pour les rÃ©sultats dÃ©taillÃ©s.

**Comparaison avec qwen25-1024d (production)**:
- Overall Quality: ? vs 68.2%
- Instruction-Aware: ? vs 94.9%
- Code Understanding: ? vs 84.5%
- Model Size: ~128MB vs 65MB
- RAM Usage: ? vs 3.3GB total

## ğŸ”§ Usage

### Test Simple

```bash
python test_colbert.py
```

### Programmatique

```python
from pylate import models, retrieve

# Charger modÃ¨le
model = models.ColBERT(
    model_name_or_path="mixedbread-ai/mxbai-edge-colbert-v0-32m"
)

# Encoder
query = "How do I install Python?"
docs = ["Steps to setup Python", "Installing Java"]

queries_emb = model.encode([query], is_query=True)
docs_emb = model.encode(docs, is_query=False)

# Score avec MaxSim
scores = retrieve.score_maxsim(
    queries_embeddings=queries_emb,
    documents_embeddings=docs_emb
)

print(scores)
```

## ğŸš€ IntÃ©gration Potentielle

### Si rÃ©sultats positifs:

**Option A** (Simple):
- Endpoint API sÃ©parÃ© `/api/colbert/embed`
- Utilisation pour cas spÃ©cifiques (code search, Q&A)
- Garde qwen25 pour usage gÃ©nÃ©ral

**Option B** (ComplÃ¨te):
- Remplacer qwen25 si qualitÃ© >> meilleure
- Adapter cache et N8N
- Requiert refactoring significatif

### Si rÃ©sultats neutres/nÃ©gatifs:

- Documenter comme "testÃ© mais pas retenu"
- Garder pour rÃ©fÃ©rence future
- Focus sur modÃ¨les single-vector

## ğŸ“š Documentation

- **Guide ColBERT**: `../../COLBERT_TESTING.md`
- **Blog Mixedbread**: https://www.mixedbread.com/blog/edge-v0
- **HuggingFace**: https://huggingface.co/mixedbread-ai/mxbai-edge-colbert-v0-32m
- **PyLate**: https://github.com/lightonai/pylate

## ğŸ”„ Statut

- [x] Installation pylate âœ…
- [x] Test simple exÃ©cutÃ© âœ…
- [x] Test multilingue exÃ©cutÃ© âœ…
- [x] RÃ©sultats analysÃ©s âœ…
- [x] **DÃ©cision prise: âŒ REJETÃ‰ pour intÃ©gration** (RAM overhead)

**Voir [DECISION.md](./DECISION.md) pour l'analyse complÃ¨te**

---

## ğŸ“Š RÃ©sultats Finaux

**QualitÃ©:** 94.4% (meilleur modÃ¨le testÃ©!)
**Instruction-Aware:** 95.6% (+0.7% vs qwen25)
**Code Understanding:** 94.0% (+9.5% vs qwen25)
**Multilingue:** FR/ES/DE excellent (< 4% dÃ©gradation)

**Verdict:** âŒ **RejetÃ© pour overhead RAM** (+964MB, 15x plus gros que qwen25)

MalgrÃ© l'excellente qualitÃ© (+26.2% vs qwen25), le modÃ¨le est **trop gourmand en RAM** pour notre use case edge deployment.

---

**TestÃ© le**: 2025-10-18
**Architecture**: Multi-vector (ColBERT)
**Comparaison**: vs qwen25-1024d (single-vector)
**Statut**: ArchivÃ© comme rÃ©fÃ©rence "gold standard"