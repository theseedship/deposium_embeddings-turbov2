# Performance Optimization Environment Variables
ENABLE_TORCH_COMPILE=1
# PyTorch Threading Optimization (Railway vCPU: 4 threads recommended)
OMP_NUM_THREADS=4
MKL_NUM_THREADS=4
TORCH_NUM_THREADS=4

# CPU Affinity (better cache locality)
KMP_AFFINITY=granularity=fine,compact,1,0
KMP_BLOCKTIME=0

# ONNX Runtime Optimization
ORT_NUM_THREADS=4
ORT_ENABLE_CPU_FP16_OPS=1

# Python Optimization
PYTHONDONTWRITEBYTECODE=1
PYTHONUNBUFFERED=1

# FastAPI/Uvicorn
UVICORN_WORKERS=1
UVICORN_PORT=11435
UVICORN_HOST=0.0.0.0

# Hugging Face Token (required for gated models like Gemma)
HF_TOKEN=hf_your_token_here

# Model Cache (Railway volume at /app/models)
# Note: TRANSFORMERS_CACHE is deprecated in transformers v5, use HF_HOME only
HF_HOME=/app/models

# ============================================================================
# Model Configuration
# ============================================================================

# Default models used when no model is specified in API requests
DEFAULT_EMBEDDING_MODEL=m2v-bge-m3-1024d
DEFAULT_RERANK_MODEL=qwen3-rerank

# HuggingFace Hub IDs for each model (override to use custom models)
HF_MODEL_M2V_BGE_M3=tss-deposium/m2v-bge-m3-1024d
HF_MODEL_BGE_M3_ONNX=gpahal/bge-m3-onnx-int8
HF_MODEL_GEMMA_768D=tss-deposium/gemma-deposium-768d
HF_MODEL_QWEN3_EMBED=Qwen/Qwen3-Embedding-0.6B

# ============================================================================
# VRAM Management
# ============================================================================

# Maximum VRAM to use in MB (default 5000 for 6GB GPU, keeps 1GB margin)
VRAM_LIMIT_MB=5000

# Time in seconds before unloading inactive models (default 180 = 3 minutes)
AUTO_UNLOAD_MODELS_TIME=180

# ============================================================================
# Authentication
# ============================================================================

# API key for external requests (leave empty to disable auth in dev mode)
# EMBEDDINGS_API_KEY=your_secret_api_key_here
